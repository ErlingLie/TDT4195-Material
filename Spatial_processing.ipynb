{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Spatial processing\n",
    "This notebook will cover image processing in the spatial domain for the image processing part of TDT4195."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import statements\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interact, interact_manual, FloatSlider\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Sampling and quantization\n",
    "\n",
    "The world around us is analog or continous, while digital images are discrete. In order to produce a digital image from a continous signal we must do the two processes called sampling and quantization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Sampling\n",
    "In image processing sampling is the process of reducing the continous spatial signal to a discrete set of pixels. Its effect can be illustrated by excessively undersampling an image and looking at the result. An undersampled image will appear pixelated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c633e7fc4e43699d6c2e95c0377760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='x', max=8, min=1), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sample(x):\n",
    "    image = plt.imread(\"images/strawberry.jpg\")[::2, ::2]\n",
    "    x = 2**(8-x)\n",
    "    plt.figure(figsize = (10,10))\n",
    "    plt.imshow(image[::x, ::x])\n",
    "    plt.show()\n",
    "    \n",
    "_ = interact(sample,x=widgets.IntSlider(min=1, max=8, step=1, value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Quantization\n",
    "Whereas sampling is the process discretizising image in the spatial extent to a discrete set of pixels, quantization is the process of reducing the continous range of possible color intensity values to a discrete set of intensities. Often we use uint8 to represent color values. That gives us a range of 256 different color intensity levels. Other times we may require a higher integer precision for a more true representation, or we may reduce the number of possible intensity levels in order to compress the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e5e78cf4204499a8d0210e29fbd0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='color_bits', max=8, min=1), Output()), _dom_classes=('wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def quantize(color_bits):\n",
    "    image = plt.imread(\"images/strawberry.jpg\")[::2, ::2]\n",
    "    x = 2**(8-color_bits)\n",
    "    plt.figure(figsize = (10,10))\n",
    "    plt.imshow(image - image % x)\n",
    "    plt.show()\n",
    "    \n",
    "_ = interact(quantize,color_bits=widgets.IntSlider(min=1, max=8, step=1, value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Intensity transformations\n",
    "Some of the simplest image processing operations are intensity transformations or point processing operations. Intensity transformations are image operations that operate on each pixel individually without respect to the neighbouring pixels. This is in contrast to neighbourhood processing, which assesses the neighbourhood around each pixel in order to transform it.\n",
    "\n",
    "In intensity transforms each pixel is assigned a new color according to a scalar function:\n",
    "$$c' = f(c)$$\n",
    "\n",
    "The function f can vary alot depending on what we want to do. The following code snippets display some common mathematical operations that we can apply to images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Image historgram\n",
    "When we apply intensity transforms we are usually interested in how the transformation affectes the image histogram. An image histogram is simply a histogram that displays the image distribution over all intensity values. We can calculate and display image histograms with matplotlib.\n",
    "\n",
    "We can get a lot of usefull information from assessing the image histogram. Images where most values are at the lower end of the distribution are dark, images with mostly high values are bright, images intensity values spread over a short span have low contrast and images with values spread over all possible intensities are high in contrast. Ideally we want a flat image-histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4a5e3280d74f428690cc17d1a00480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image_path', options=('lake', 'mountain', 'alpine', 'sunset', 'boa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_image_and_histogram(image_path):\n",
    "    image = plt.imread(\"images/bw_\" + image_path + \".jpg\")[::2,::2,0]\n",
    "    plt.figure(figsize = (12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image, cmap = \"gray\")\n",
    "    plt.subplot(1,2,2)\n",
    "    \n",
    "    #Always remeber to flatten the image array before calculating the histogram\n",
    "    _ = plt.hist(image.reshape(-1), bins=64)\n",
    "    plt.title(\"Image histogram\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "_ = interact(display_image_and_histogram, image_path = [\"lake\", \"mountain\", \"alpine\", \"sunset\", \"boat\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Intuition - Window and level transform\n",
    "We can transform an image's brightness and contrast by transforming the image-historgram. A simple method is the window/level-transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ba60cf7c6848998b6c86490f4130a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image_path', options=('lake', 'mountain', 'alpine', 'sunset', 'boa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_window_level_transform(window, level):\n",
    "    half_window = window/2\n",
    "    y = np.zeros(256)\n",
    "    for x in range(256):\n",
    "        if(x < level - half_window):\n",
    "            y[x] = 0\n",
    "        elif (x >= level + half_window):\n",
    "            y[x] = 255\n",
    "        else:\n",
    "            y[x] = (x - level + half_window) * 255/window\n",
    "    return y.astype(np.uint8)\n",
    "\n",
    "def window_transform_image(image_path, window, level):\n",
    "    transform = make_window_level_transform(window, level)\n",
    "    image = plt.imread(\"images/bw_\" + image_path + \".jpg\")[::2,::2,0]\n",
    "    image = transform[image[:,:]]\n",
    "    plt.figure(figsize=(18,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    image[0,0] = 254   #Necessary so that matplotlib doesn't normalize all white images to black\n",
    "    plt.imshow(image, cmap = \"gray\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(np.arange(256), transform)\n",
    "    plt.title(\"Transformation function\")\n",
    "    plt.show()\n",
    "    \n",
    "    _ = plt.hist(image.reshape(-1), bins = 64)\n",
    "    plt.title(\"Image histogram\")\n",
    "    plt.show()\n",
    "    \n",
    "_ = interact_manual(window_transform_image, image_path = [\"lake\", \"mountain\", \"alpine\", \"sunset\", \"boat\"],\\\n",
    "                    window = widgets.IntSlider(min = 0, max = 256, step = 2, value=256),\\\n",
    "             level = widgets.IntSlider(min = 0, max = 256, step = 1, value=127))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Gamma transform\n",
    "Interactive display of how the gamma-transform affects an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0b1d43b6024baf83b6b1c005473a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='gamma', max=5.0, min=0.01, step=0.01), Button(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gamma_transform(gamma):\n",
    "    image = plt.imread(\"images/bw_lake.jpg\")[::2,::2,0]  \n",
    "    image = image/255.\n",
    "    image = image**gamma\n",
    "    plt.figure(figsize = (8,4))\n",
    "    plt.imshow(image, cmap = \"gray\")\n",
    "    plt.show()\n",
    "    image = (image * 255).astype(np.uint8).reshape(-1)\n",
    "    plt.figure(figsize = (12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    _ = plt.hist(image, bins=64)\n",
    "    plt.title(\"Image histogram\")\n",
    "    plt.subplot(1,2,2)\n",
    "    x = np.arange(256)\n",
    "    y = ((x/255.)**gamma)*255\n",
    "    plt.plot(x,y)\n",
    "    plt.title(\"Transformation function\")\n",
    "    plt.show()\n",
    "\n",
    "_ = interact_manual(gamma_transform,  gamma=FloatSlider(min=0.01, max=5.0, step=1e-2, value=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Log and inverse log transform\n",
    "Interactive display of the log and inverse log transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8b03ecbb0645298ac2df07b8a09859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='transform', options=('log', 'identity', 'inverse log'), value='log…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def log_transform(transform):\n",
    "    image = plt.imread(\"images/bw_lake.jpg\")[:,:,0]  \n",
    "    image = image/255.\n",
    "    if transform == \"log\":\n",
    "        c = 1/np.log(2)\n",
    "        image = c*np.log(image + 1)\n",
    "    elif transform == \"inverse log\":\n",
    "        c = 1/np.log(2)\n",
    "        image = np.exp(image/c) - 1\n",
    "    else:\n",
    "        pass\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.imshow(image, cmap = \"gray\")\n",
    "    plt.show()\n",
    "    image = (image * 255).astype(np.uint8).reshape(-1)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    _ = plt.hist(image, bins=64)\n",
    "    plt.title(\"Image histogram\")\n",
    "    plt.show()\n",
    "\n",
    "_ = interact_manual(log_transform, transform = [\"log\", \"identity\", \"inverse log\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Histogram equalization\n",
    "Histogram equalization is a method used in image processing to improve contrast in images. It stretches the dynamic range for the most frequent intensity values, effectively spreading them out over the whole range of possible values. Normally this will imporve the contrast of images, brighten dark images and darken bright images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21ee765c26d4faabb42943e96bfa894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image_name', options=('alpine', 'sunset', 'boat', 'lake', 'mountai…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def histogram_eq(image):\n",
    "    #First we calculate the histogram.\n",
    "    hist, bins = np.histogram(image[:,:], 256)\n",
    "    \n",
    "    #Then we calculate the cumulative histogram\n",
    "    cumulative_hist = np.zeros((256), dtype = np.int)\n",
    "    cumulative_hist[0] = hist[0]\n",
    "    for i in range(1, 256):\n",
    "        cumulative_hist[i] = cumulative_hist[i-1] + hist[i]\n",
    "    \n",
    "    #Then we normalize the histogram to [0., 1.]\n",
    "    normalized_cumulative_hist = cumulative_hist.astype(float)\n",
    "    normalized_cumulative_hist /= normalized_cumulative_hist[-1]\n",
    "    \n",
    "    #Then we construct an intensity mapping table by multiplying with the maximum intensity value\n",
    "    table = (normalized_cumulative_hist * 255).astype(np.uint8)\n",
    "    \n",
    "    #Lastly we create the new image by mapping each of the old intensities to the new corresponding intensity\n",
    "    new_im = table[image[:,:]]\n",
    "    return new_im, table\n",
    "\n",
    "def histogram_transform_image(image):\n",
    "    new_image, transform = histogram_eq(image)\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image, cmap = \"gray\")\n",
    "    plt.title(\"Original image\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(new_image, cmap = \"gray\")\n",
    "    plt.title(\"Transformed image\")\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(16,3))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.plot(np.arange(256), transform)\n",
    "    plt.title(\"Transformation function\")\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    _ = plt.hist(image.reshape(-1), bins = 64)\n",
    "    plt.title(\"Original image histogram\")\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    _ = plt.hist(new_image.reshape(-1), bins = 64)\n",
    "    plt.title(\"Transformed image histogram\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def window_level_then_histogram(image_name, window, level):\n",
    "    window_level_transform = make_window_level_transform(window, level)\n",
    "    image = plt.imread(\"images/bw_\" + image_name + \".jpg\")[:,:,0]\n",
    "    image = window_level_transform[image]\n",
    "    histogram_transform_image(image)\n",
    "    \n",
    "    \n",
    "def gamma_then_histogram(image_name, gamma):\n",
    "    image = plt.imread(\"images/bw_\" + image_name + \".jpg\")[:,:,0]\n",
    "    image = (image/255)**gamma\n",
    "    image = (image*255).astype(np.uint8)\n",
    "    histogram_transform_image(image)\n",
    "#_ = interact_manual(window_level_then_histogram, image_name = [\"lake\", \"mountain\", \"alpine\", \"sunset\", \"boat\"],\\\n",
    "#                   window = widgets.IntSlider(min = 0, max = 256, step = 2, value=256),\\\n",
    "#                   level = widgets.IntSlider(min = 0, max = 256, step = 1, value=127))\n",
    "\n",
    "\n",
    "_ = interact_manual(gamma_then_histogram, image_name = [\"alpine\", \"sunset\", \"boat\", \"lake\", \"mountain\", ],\\\n",
    "                    gamma=FloatSlider(min=0.01, max=5.0, step=1e-2, value=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Neighborhood filtering\n",
    "Neighborhood filtering covers image processing techniques that transform each pixel with respect to its neighbors. The common operation is image convolution. By varying the convolution kernels we can achieve many different effects. \n",
    "\n",
    "This tool is supposed to be an interactive display of different convolution kernels. Most of the kernels can be found [here](https://en.wikipedia.org/wiki/Kernel_(image_processing)). Common operations are image smoothening, image sharpening and edge detection. Normally, we apply image smoothening before edge detection. This is because edge detection is basically the same as derivating the image, and taking the derivative of a noisy signal will yield even more noise. If we first smoothen the image, we will eliminate some of the noise before applying the edge detection. Smoothening with a small kernel will allow you to detect fine edges, while applying a large smoothening kernel will allow you to detect only the cleares edges.\n",
    "\n",
    "Try different combinations of covolution kernels and assess the results. Convolving the **boat** image with **box_9** and **sobel_y** is a good place to start. Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387c054a84bf4bc88d348c8fdfd77e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image_name', options=('butterfly', 'alpine', 'boat', 'lake', 'moun…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convolve_image(image, kernel):\n",
    "    h, w = image.shape[:2]\n",
    "    kernel_size= kernel.shape[0]\n",
    "    \n",
    "    #Rotate 180 degrees in order to perform convolution and not correlation\n",
    "    kernel = np.rot90(np.rot90(kernel))\n",
    "    pad = (kernel_size - 1) // 2\n",
    "    \n",
    "    image = np.pad(image, pad_width = ((pad,pad), (pad,pad)), mode = \"constant\")\n",
    "    \n",
    "    output = np.zeros_like(image)\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            im_slice = image[y: y+kernel_size, x: x + kernel_size]\n",
    "            \n",
    "            value = np.sum(im_slice*kernel, axis = (0,1))\n",
    "            output[y + pad, x + pad] = value\n",
    "\n",
    "    return output\n",
    "\n",
    "kernel_map = {\n",
    "    \"identity\"   : np.array([[0,0,0], [0,1,0], [0,0,0]]),\n",
    "    \"gaussian_3\" : np.array([[1,2,1], [2,4,2], [1,2,1]])/16,\n",
    "    \"gaussian_5\" : np.array([[1,4,6,4,1], [4,16,24,16,4],\\\n",
    "                             [6,24,36,24,6], [4,16,24,16,4], [1,4,6,4,1]]) /256,\n",
    "    \"gaussian_7\" : np.array([[0,0,1,2,1,0,0], [0,3,13,22,13,3,0], [1,13,59,97,69,13,1],\\\n",
    "                            [2,22,97,159,97,22,2], [1,13,59,97,59,13,1], [0,3,13,22,13,3,0],\\\n",
    "                            [0,0,1,2,1,0,0]])/1003,\n",
    "    \"box_3\"      : np.ones((3,3))/9,\n",
    "    \"box_5\"      : np.ones((5,5))/25,\n",
    "    \"box_7\"      : np.ones((7,7))/49,\n",
    "    \"box_9\"      : np.ones((9,9))/81,\n",
    "    \"edge_1\"     : np.array([[1,0,-1], [0,0,0],[-1,0,1]]),\n",
    "    \"edge_2\"     : np.array([[0,-1,0], [-1,4,-1], [0,-1,0]]),\n",
    "    \"edge_3\"     : np.array([[-1,-1,-1], [-1,8,-1], [-1,-1,-1]]),\n",
    "    \"sharpen\"    : np.array([[0,-1,0], [-1,5,-1], [0,-1,0]]),\n",
    "    \"sobel_x\"    : np.array([[1,0,-1], [2,0,-2], [1,0,-1]]),\n",
    "    \"sobel_y\"  : np.array([[1,2,1], [0,0,0], [-1,-2,-1]])\n",
    "    }\n",
    "\n",
    "def display_convolved_image(image_name, kernel_1, kernel_2):\n",
    "    image = plt.imread(\"images/bw_\" + image_name + \".jpg\")[:,:,0]\n",
    "    if image_name in [\"alpine\", \"sunset\", \"boat\", \"lake\", \"mountain\"]:\n",
    "        image = image[::2,::2] \n",
    "\n",
    "\n",
    "    output = convolve_image(image, kernel_map[kernel_1])\n",
    "    output = convolve_image(output, kernel_map[kernel_2])\n",
    "    plt.figure(figsize = (10,10))\n",
    "    plt.imshow(output, cmap = \"gray\")            \n",
    "    plt.show()     \n",
    "\n",
    "_ = interact_manual(display_convolved_image, image_name = [\"butterfly\",\"alpine\", \"boat\", \"lake\", \"mountain\"],\\\n",
    "                    kernel_1 = kernel_map.keys(), kernel_2 = kernel_map.keys())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tdt4195",
   "language": "python",
   "name": "tdt4195"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
